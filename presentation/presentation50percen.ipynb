{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a76f515a",
   "metadata": {},
   "source": [
    "# Stock Chart Pattern Recognition Using Deep Learning (CRISP-DM)\n",
    "\n",
    "This notebook follows the CRISP-DM (Cross Industry Standard Process for Data Mining) methodology to prepare stock market data for Head and Shoulders (H&S) pattern recognition using Deep Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a5f5b9",
   "metadata": {},
   "source": [
    "## 1️⃣ Business Understanding & Data Understanding\n",
    "\n",
    "Objective: Use Deep Learning to identify and predict outcomes of Head and Shoulders (H&S) and Inverse Head and Shoulders (IH&S) patterns, leveraging comprehensive Technical and Fundamental features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851fb175",
   "metadata": {},
   "source": [
    "1.1 Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7cefe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from cassandra.cluster import Cluster\n",
    "from datetime import datetime\n",
    "import time\n",
    "import importlib\n",
    "\n",
    "# Technical Analysis Libraries\n",
    "from ta.trend import EMAIndicator\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0483f4",
   "metadata": {},
   "source": [
    "## 1.2 Data Understanding\n",
    "The data comes from the SETTRADE API and is stored in a Cassandra database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df4abd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Keyspace และ Table พร้อมใช้งาน!\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1️⃣ เชื่อมต่อ Cassandra และเตรียม Keyspace/Table\n",
    "# ==========================================\n",
    "try:\n",
    "    cluster = Cluster(['127.0.0.1'], port=9042)\n",
    "    session = cluster.connect()\n",
    "    session.execute(\"\"\"\n",
    "        CREATE KEYSPACE IF NOT EXISTS stock_data\n",
    "        WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1};\n",
    "    \"\"\")\n",
    "    session.set_keyspace('stock_data')\n",
    "    \n",
    "    # ตรวจสอบและสร้าง Table หากยังไม่มี\n",
    "    session.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS candlestick_data (\n",
    "            symbol text,\n",
    "            time timestamp,\n",
    "            open float,\n",
    "            high float,\n",
    "            low float,\n",
    "            close float,\n",
    "            volume bigint,\n",
    "            value float,\n",
    "            PRIMARY KEY (symbol, time)\n",
    "        ) WITH CLUSTERING ORDER BY (time ASC);\n",
    "    \"\"\")\n",
    "    print(\"✅ Keyspace และ Table พร้อมใช้งาน!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error during Cassandra connection/setup: {e}\")\n",
    "    print(\"โปรดตรวจสอบว่า Cassandra Server (127.0.0.1:9042) ได้รันอยู่หรือไม่\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30cf21b",
   "metadata": {},
   "source": [
    "## 1.3 Data Extraction (OHLCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85647eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "❌ เกิดข้อผิดพลาดที่ไม่คาดคิด: name 'get_candlestick_data' is not defined\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2a500b4",
   "metadata": {},
   "source": [
    "## 2️⃣ Data Preparation\n",
    "\n",
    "ขั้นตอนนี้จะรวม Market Cap, Technical Grouping และ Fundamental Data เข้าด้วยกัน"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc27eae3",
   "metadata": {},
   "source": [
    "2.1 Feature Engineering: Market Cap & Technical Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef5e4556",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_technical_features_and_grouping(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"คำนวณ Market Cap (Proxy), EMA, RSI และกำหนดกลุ่มสัญญาณทางเทคนิค\"\"\"\n",
    "    \n",
    "    # --- 1. Add Market Cap column ---\n",
    "    # Market Cap Proxy = Close Price * Volume (มูลค่าการซื้อขาย)\n",
    "    df['MarketCap_Proxy'] = df['close'] * df['volume']\n",
    "    \n",
    "    # --- 2. คำนวณ Indicators ---\n",
    "    df['EMA5'] = EMAIndicator(close=df['close'], window=5, fillna=False).ema_indicator()\n",
    "    df['EMA15'] = EMAIndicator(close=df['close'], window=15, fillna=False).ema_indicator()\n",
    "    df['EMA35'] = EMAIndicator(close=df['close'], window=35, fillna=False).ema_indicator()\n",
    "    df['EMA89'] = EMAIndicator(close=df['close'], window=89, fillna=False).ema_indicator()\n",
    "    df['EMA200'] = EMAIndicator(close=df['close'], window=200, fillna=False).ema_indicator()\n",
    "    df['RSI'] = RelativeStrengthIndex(close=df['close'], window=14, fillna=False).rsi()\n",
    "    \n",
    "    # --- 3. กำหนดกลุ่มสัญญาณ (Categorization) ---\n",
    "    conditions = [\n",
    "        # a: Strong Momentum / Overbought\n",
    "        (df['close'] >= df['EMA5']) & (df['RSI'] >= 70),\n",
    "        \n",
    "        # b: Clear Uptrend\n",
    "        (df['close'] >= df['EMA35']) & (df['EMA35'] >= df['EMA89']),\n",
    "        \n",
    "        # c: Sideways above EMA89 (Short-term EMAs close together)\n",
    "        (df['close'] >= df['EMA89']) & \n",
    "        (np.abs(df['EMA5'] - df['EMA35']) / df['close'] < 0.01), # ใช้ EMA5, EMA35\n",
    "        \n",
    "        # d: Downtrend\n",
    "        (df['close'] < df['EMA89']) & (df['close'] < df['EMA200']) & (df['EMA89'] < df['EMA200']),\n",
    "        \n",
    "        # e: Crash (Strong descending order and oversold)\n",
    "        (df['close'] < df['EMA5']) & (df['EMA5'] < df['EMA15']) & (df['EMA15'] < df['EMA35']) & \n",
    "        (df['EMA35'] < df['EMA89']) & (df['EMA89'] < df['EMA200']) & (df['RSI'] <= 30)\n",
    "    ]\n",
    "    \n",
    "    choices = ['a_Overbought', 'b_ClearUptrend', 'c_SidewaysAbove89', 'd_Downtrend', 'e_Crash']\n",
    "    \n",
    "    df['Technical_Group'] = np.select(conditions, choices, default='f_Neutral')\n",
    "    \n",
    "    # --- 4. Drop NAN Data ---\n",
    "    # Drop rows ที่เป็น NaN (เกิดจากการคำนวณ EMA200)\n",
    "    df_cleaned = df.dropna().copy()\n",
    "    \n",
    "    print(f\"✅ NaN Data Dropped: {len(df) - len(df_cleaned)} rows removed (Initial trading period / Indicator lookback)\")\n",
    "    \n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80134c22",
   "metadata": {},
   "source": [
    "## 2.2 Feature Engineering: Fundamental Data (Mock)\n",
    "\n",
    "เนื่องจากข้อมูล Fundamental (EPS, PE, PBV, Yield) ไม่ได้รวมอยู่ใน Table candlestick_data เราจะสร้าง Mock-up Data โดยอิงจาก Interpretation ของคุณ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85d61343",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Fundamental Data Added (Mocked based on Interpretation)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mdf_raw\u001b[49m.empty:\n\u001b[32m     27\u001b[39m     df_temp_features = create_technical_features_and_grouping(df_raw)\n\u001b[32m     28\u001b[39m     df_final_features = add_fundamental_data(df_temp_features)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_raw' is not defined"
     ]
    }
   ],
   "source": [
    "def add_fundamental_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"จำลองการเพิ่มข้อมูล Fundamental (PE, PBV, Yield) ตามเงื่อนไขที่กำหนด\"\"\"\n",
    "    \n",
    "    # 1. EPS (Negative, indicating a loss) - ใช้ค่าสุ่มเล็กน้อย\n",
    "    df['EPS'] = np.random.uniform(-0.5, 0.5, size=len(df))\n",
    "    \n",
    "    # 2. PE (Zero due to company losses)\n",
    "    # ถ้า EPS <= 0 ให้ PE = 0.0, ถ้ามีกำไร (EPS > 0) ให้คำนวณ PE จริง\n",
    "    df['PE'] = df.apply(\n",
    "        lambda row: 0.0 if row['EPS'] <= 0 else (row['close'] / row['EPS']), \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # 3. PBV (Relatively high: 1.5 - 5.0)\n",
    "    df['PBV'] = np.random.uniform(1.5, 5.0, size=len(df))\n",
    "    \n",
    "    # 4. PercentYield (Dividend per share / stock price)\n",
    "    df['PercentYield'] = np.random.uniform(0.0, 0.05, size=len(df))\n",
    "    \n",
    "    # Clean up PE where it might be Inf\n",
    "    df['PE'].replace([np.inf, -np.inf], 0.0, inplace=True)\n",
    "    \n",
    "    print(\"✅ Fundamental Data Added (Mocked based on Interpretation)\")\n",
    "    return df\n",
    "\n",
    "if not df_raw.empty:\n",
    "    df_temp_features = create_technical_features_and_grouping(df_raw)\n",
    "    df_final_features = add_fundamental_data(df_temp_features)\n",
    "    \n",
    "    df_model_ready = df_final_features.copy()\n",
    "    \n",
    "    print(\"\\n--- Summary of Data Preparation (Ready for DL) ---\")\n",
    "    print(df_model_ready[['close', 'EMA89', 'RSI', 'MarketCap_Proxy', 'Technical_Group', 'PE']].tail(5).to_markdown(index=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35376542",
   "metadata": {},
   "source": [
    "## 3️⃣ Modeling & 4️⃣ Evaluation (Data Labeling Stage)\n",
    "\n",
    "ในส่วนนี้ เราจะแสดงการใช้ Logic Head and Shoulders เพื่อเป็น Data Labeling (Target) สำหรับการฝึกโมเดล Deep Learning ซึ่งเป็นส่วนสำคัญของการนำเสนอ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efca833c",
   "metadata": {},
   "source": [
    "## 3.1 Head and Shoulders Detection and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a919cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# ฟังก์ชันวาด H&S Pattern ด้วย Plotly\n",
    "# ==========================================================\n",
    "def plot_classic_pattern(df: pd.DataFrame, patterns: list, symbol: str):\n",
    "    \n",
    "    # 1. สร้าง Candlestick Figure พื้นฐาน\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Candlestick(\n",
    "        x=df.index, open=df['open'], high=df['high'], low=df['low'], close=df['close'], name='Price'\n",
    "    ))\n",
    "    \n",
    "    # ปรับ Layout\n",
    "    fig.update_layout(\n",
    "        title=f'📈 {symbol} - Head & Shoulders Detection (Data Labeling)',\n",
    "        xaxis_rangeslider_visible=False,\n",
    "        height=700,\n",
    "        template='plotly_white'\n",
    "    )\n",
    "\n",
    "    # 2. วาด Pattern และ Neckline\n",
    "    for i, pattern in enumerate(patterns):\n",
    "        l_idx, h_idx, r_idx = pattern['left_idx'], pattern['head_idx'], pattern['right_idx']\n",
    "        \n",
    "        l_time, h_time, r_time = df.index[l_idx], df.index[h_idx], df.index[r_idx]\n",
    "        \n",
    "        line_color = '#EF553B' if pattern['type'] == 'H&S' else '#00CC96'\n",
    "        \n",
    "        # วาดเส้น Pattern (ไหล่ซ้าย-หัว-ไหล่ขวา)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[l_time, h_time, r_time],\n",
    "            y=[df['close'].iloc[l_idx], df['close'].iloc[h_idx], df['close'].iloc[r_idx]],\n",
    "            mode='lines+markers',\n",
    "            line=dict(color=line_color, width=3),\n",
    "            marker=dict(size=8, symbol='circle'),\n",
    "            name=f\"{pattern['type']} {i+1}\",\n",
    "            showlegend=True\n",
    "        ))\n",
    "        \n",
    "        # 3. Annotations\n",
    "        fig.add_annotation(\n",
    "            x=h_time, y=df['high'].iloc[h_idx] * 1.01,\n",
    "            text=f\"{pattern['type']} Detected\",\n",
    "            showarrow=True,\n",
    "            arrowhead=2,\n",
    "            font=dict(color=line_color, size=10, weight='bold'),\n",
    "            yshift=10 if pattern['type'] == 'H&S' else -10\n",
    "        )\n",
    "        \n",
    "    fig.show()\n",
    "\n",
    "# --- Main Detection Logic ---\n",
    "if 'df_model_ready' in locals() and not df_model_ready.empty:\n",
    "    \n",
    "    print(\"\\n--- 📉 Applying Classic Detector for DL Label Generation ---\")\n",
    "    \n",
    "    # 🚨 ใช้ฟังก์ชันตรวจจับ\n",
    "    classic_patterns = detect_head_shoulders(df_model_ready, distance=10, tolerance=0.04)\n",
    "    \n",
    "    print(f\"✅ พบรูปแบบ H&S/IH&S ทั้งหมด: {len(classic_patterns)} จุด\")\n",
    "    \n",
    "    if classic_patterns:\n",
    "        plot_classic_pattern(df_model_ready, classic_patterns, symbol=STOCK_SYMBOL)\n",
    "    else:\n",
    "        print(\"💡 ไม่พบรูปแบบ Head & Shoulders หรือ Inverse Head & Shoulders ในข้อมูลที่กำหนด\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b052edb2",
   "metadata": {},
   "source": [
    "## 5️⃣ Deployment (Final Feature Preparation for DL)\n",
    "\n",
    "ขั้นตอนนี้เป็นการแปลงข้อมูลที่เตรียมไว้ (Price, Volume, Technical, Fundamental) ให้อยู่ในรูปแบบ 3D Array (Time Series Sequence) ที่พร้อมป้อนเข้าโมเดล Deep Learning (CNN-LSTM หรือ Transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a8e14f",
   "metadata": {},
   "source": [
    "## 5.1 Data Scaling and Sequence Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e31a2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# 🤖 Final Step: Preparing 3D Array for Deep Learning Model\n",
    "# ------------------------------------------------------------------\n",
    "if 'df_model_ready' in locals() and not df_model_ready.empty:\n",
    "    \n",
    "    print(\"\\n--- 🧠 Deployment Setup: Data Scaling and Sequence Creation ---\")\n",
    "    \n",
    "    # 1. เลือก Features ทั้งหมดที่จะใช้ป้อนเข้าโมเดล DL\n",
    "    features = [\n",
    "        'open', 'high', 'low', 'close', 'volume', 'MarketCap_Proxy', \n",
    "        'EMA5', 'EMA15', 'EMA35', 'EMA89', 'EMA200', 'RSI',\n",
    "        'EPS', 'PE', 'PBV', 'PercentYield' \n",
    "    ]\n",
    "    \n",
    "    df_dl = df_model_ready[features].copy()\n",
    "    \n",
    "    # 2. Normalization (MinMaxScaler)\n",
    "    print(f\"📐 Scaling {len(features)} features...\")\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    df_scaled_values = scaler.fit_transform(df_dl)\n",
    "    df_scaled = pd.DataFrame(df_scaled_values, columns=features, index=df_dl.index)\n",
    "    \n",
    "    # 3. Creating Sequences (Sliding Window)\n",
    "    # โมเดลจะมองข้อมูลย้อนหลัง 30 วัน (SEQUENCE_LENGTH) เพื่อทำนายวันถัดไป\n",
    "    def create_sequences(data, sequence_length):\n",
    "        xs = []\n",
    "        for i in range(len(data) - sequence_length):\n",
    "            x = data.iloc[i:(i + sequence_length)]\n",
    "            xs.append(x.values)\n",
    "        return np.array(xs)\n",
    "\n",
    "    X_sequences = create_sequences(df_scaled, SEQUENCE_LENGTH)\n",
    "    \n",
    "    # 4. Creating Labels (Target Y) - Mock for Demo\n",
    "    # การทำนายง่ายๆ: ราคาปิดใน 5 วันข้างหน้าสูงกว่าวันนี้หรือไม่ (Binary Classification)\n",
    "    FUTURE_PREDICT_DAYS = 5\n",
    "    y_raw = (df_dl['close'].shift(-FUTURE_PREDICT_DAYS) > df_dl['close']).astype(int)\n",
    "    \n",
    "    # ปรับ Label ให้เข้ากับ Sequence length\n",
    "    y_labels = y_raw.iloc[SEQUENCE_LENGTH:].values\n",
    "    y_labels = y_labels[:-FUTURE_PREDICT_DAYS].copy() \n",
    "    \n",
    "    # ตัด X_sequences ให้มีจำนวน Sample เท่ากับ Y_labels\n",
    "    X_sequences = X_sequences[:-FUTURE_PREDICT_DAYS]\n",
    "\n",
    "    # 5. สรุปผลลัพธ์\n",
    "    print(\"\\n--- DL Model Input Dimensions ---\")\n",
    "    print(f\"Sequence Length (Time Steps): {SEQUENCE_LENGTH} วัน\")\n",
    "    print(f\"Number of Features: {len(features)} ตัว\")\n",
    "    print(f\"Input Data Shape (Samples, Time Steps, Features): {X_sequences.shape}\")\n",
    "    print(f\"Label Data Shape (Samples): {y_labels.shape}\")     \n",
    "    print(\"\\n💡 ข้อมูลถูกแปลงเป็น 3D Array เรียบร้อยแล้ว พร้อมสำหรับการฝึกโมเดล Deep Learning.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
