{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18371955",
   "metadata": {},
   "source": [
    "# Stock Char Pattern Recognition Using Deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc2fc3e",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a87c79c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from cassandra.cluster import Cluster\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# üö® ‡πÄ‡∏û‡∏¥‡πà‡∏° Conv1D, MaxPooling1D, ‡πÅ‡∏•‡∏∞ Flatten ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö CNN-LSTM Hybrid Model\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense, Conv1D, MaxPooling1D, Flatten \n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# üö® ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏° import ‡∏ô‡∏µ‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö H&S\n",
    "from scipy.signal import find_peaks \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6c5766",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4e1892c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candlestick_data(symbol: str, limit: int = 3000):\n",
    "    \"\"\"‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ó‡πà‡∏á‡πÄ‡∏ó‡∏µ‡∏¢‡∏ô‡∏à‡∏≤‡∏Å Cassandra ‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö\"\"\"\n",
    "    try:\n",
    "        cluster = Cluster(['127.0.0.1'], port=9042)\n",
    "        session = cluster.connect('data_stock')\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to Cassandra: {e}\")\n",
    "        raise ConnectionRefusedError(\"Could not connect to Cassandra. Check if it's running.\")\n",
    "\n",
    "    query = f\"\"\"\n",
    "        SELECT time, open_price, high_price, low_price, close_price, volume\n",
    "        FROM candlestick_data\n",
    "        WHERE symbol='{symbol}'\n",
    "        ORDER BY time DESC\n",
    "        LIMIT {limit} \n",
    "    \"\"\"\n",
    "    rows = session.execute(query)\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(f\"No data found for {symbol}\")\n",
    "\n",
    "    df.columns = df.columns.str.lower().str.strip()\n",
    "    df.rename(columns={'open_price': 'open', 'high_price': 'high', 'low_price': 'low', 'close_price': 'close'}, inplace=True)\n",
    "    df = df.sort_values('time')\n",
    "    df.set_index('time', inplace=True)\n",
    "    \n",
    "    df[['open', 'high', 'low', 'close', 'volume']] = df[['open', 'high', 'low', 'close', 'volume']].astype(float)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275bf67b",
   "metadata": {},
   "source": [
    "# 3Ô∏è‚É£ ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö Head & Shoulders (H&S/IH&S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "454c6d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_head_shoulders(df, distance=5, tolerance=0.05):\n",
    "    \"\"\"‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö H&S ‡πÅ‡∏•‡∏∞ IH&S ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏´‡∏≤ Neckline ‡πÅ‡∏•‡∏∞ Breakout\"\"\"\n",
    "    prices = df['close'].values\n",
    "    peaks, _ = find_peaks(prices, distance=distance)\n",
    "    troughs, _ = find_peaks(-prices, distance=distance)\n",
    "\n",
    "    patterns = []\n",
    "    \n",
    "    # H&S (‡πÑ‡∏´‡∏•‡πà-‡∏´‡∏±‡∏ß-‡πÑ‡∏´‡∏•‡πà) - ‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏Ç‡∏≤‡∏¢ (Bearish)\n",
    "    for i in range(2, len(peaks)):\n",
    "        l, h, r = peaks[i-2], peaks[i-1], peaks[i]\n",
    "        if r >= len(prices) - 1: continue \n",
    "            \n",
    "        left, head, right = prices[l], prices[h], prices[r]\n",
    "        \n",
    "        if head > left and head > right and abs(left - right) / head < tolerance:\n",
    "            trough1_idx = np.argmin(prices[l:h]) + l\n",
    "            trough2_idx = np.argmin(prices[h:r]) + h\n",
    "\n",
    "            neck_end_price = prices[trough2_idx]\n",
    "            neck_start_price = prices[trough1_idx]\n",
    "            neck_slope = (neck_end_price - neck_start_price) / (trough2_idx - trough1_idx)\n",
    "            \n",
    "            post_pattern_prices = prices[trough2_idx + 1:]\n",
    "            t_diff = np.arange(1, len(post_pattern_prices) + 1)\n",
    "            neckline_series = neck_end_price + neck_slope * t_diff\n",
    "            \n",
    "            breakout_points = np.where(post_pattern_prices < neckline_series)[0]\n",
    "            \n",
    "            if len(breakout_points) > 0:\n",
    "                break_idx = trough2_idx + 1 + breakout_points[0]\n",
    "                \n",
    "                # ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Target ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏Å H&S: ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á‡∏Ç‡∏≠‡∏á Head ‡∏à‡∏≤‡∏Å Neckline ‡∏ó‡∏µ‡πà‡∏à‡∏∏‡∏î Head\n",
    "                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏≤‡∏Ñ‡∏≤ Neckline ‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏à‡∏∏‡∏î Head (h)\n",
    "                neckline_at_head = neck_start_price + neck_slope * (h - trough1_idx)\n",
    "                target_height = head - neckline_at_head \n",
    "                target_price = prices[break_idx] - target_height\n",
    "                \n",
    "                patterns.append({\n",
    "                    \"type\": \"H&S\", \n",
    "                    \"l\": l, \"h\": h, \"r\": r, \n",
    "                    \"t1\": trough1_idx, \"t2\": trough2_idx, \n",
    "                    \"break_idx\": break_idx,\n",
    "                    \"target_price\": target_price \n",
    "                })\n",
    "\n",
    "    # IH&S (‡πÑ‡∏´‡∏•‡πà-‡∏´‡∏±‡∏ß-‡πÑ‡∏´‡∏•‡πà‡∏Å‡∏•‡∏±‡∏ö‡∏´‡∏±‡∏ß) - ‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡∏ã‡∏∑‡πâ‡∏≠ (Bullish)\n",
    "    for i in range(2, len(troughs)):\n",
    "        l, h, r = troughs[i-2], troughs[i-1], troughs[i]\n",
    "        if r >= len(prices) - 1: continue\n",
    "            \n",
    "        left, head, right = prices[l], prices[h], prices[r]\n",
    "        \n",
    "        if head < left and head < right and abs(left - right) / abs(head) < tolerance:\n",
    "            \n",
    "            peak1_idx = np.argmax(prices[l:h]) + l\n",
    "            peak2_idx = np.argmax(prices[h:r]) + h\n",
    "\n",
    "            neck_end_price = prices[peak2_idx]\n",
    "            neck_start_price = prices[peak1_idx]\n",
    "            neck_slope = (neck_end_price - neck_start_price) / (peak2_idx - peak1_idx)\n",
    "            \n",
    "            post_pattern_prices = prices[peak2_idx + 1:]\n",
    "            \n",
    "            t_diff = np.arange(1, len(post_pattern_prices) + 1)\n",
    "            neckline_series = neck_end_price + neck_slope * t_diff\n",
    "            \n",
    "            breakout_points = np.where(post_pattern_prices > neckline_series)[0]\n",
    "            \n",
    "            if len(breakout_points) > 0:\n",
    "                break_idx = peak2_idx + 1 + breakout_points[0]\n",
    "                \n",
    "                # ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Target ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏Å IH&S\n",
    "                neckline_at_head = neck_start_price + neck_slope * (h - peak1_idx)\n",
    "                target_height = neckline_at_head - head\n",
    "                target_price = prices[break_idx] + target_height\n",
    "                \n",
    "                patterns.append({\n",
    "                    \"type\": \"IH&S\", \n",
    "                    \"l\": l, \"h\": h, \"r\": r, \n",
    "                    \"t1\": peak1_idx, \"t2\": peak2_idx, \n",
    "                    \"break_idx\": break_idx,\n",
    "                    \"target_price\": target_price \n",
    "                })\n",
    "    return patterns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f9fd10",
   "metadata": {},
   "source": [
    "# 4Ô∏è‚É£ ‡∏™‡∏£‡πâ‡∏≤‡∏á Label ‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á (0=‡∏•‡∏á/‡∏Ñ‡∏á‡∏ó‡∏µ‡πà, 1=‡∏Ç‡∏∂‡πâ‡∏ô)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e129673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_direction_labels(df_close: pd.Series, future_days: int = 1):\n",
    "    \"\"\"\n",
    "    ‡∏™‡∏£‡πâ‡∏≤‡∏á Label ‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤: 1 ‡∏ñ‡πâ‡∏≤ Close Price ‡πÉ‡∏ô 'future_days' ‡∏ß‡∏±‡∏ô‡∏Ç‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏Ç‡∏∂‡πâ‡∏ô, 0 ‡∏ñ‡πâ‡∏≤‡∏•‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏á‡∏ó‡∏µ‡πà\n",
    "    \"\"\"\n",
    "    future_price = df_close.shift(-future_days)\n",
    "    labels = (future_price > df_close).astype(int)\n",
    "    \n",
    "    return labels[:-future_days] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c25104f",
   "metadata": {},
   "source": [
    "# 5Ô∏è‚É£ ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Deep Learning (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö 2 Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa1f18a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_create_sequences(df, labels, seq_len=30):\n",
    "    features_cols = ['open', 'high', 'low', 'close', 'volume']\n",
    "    \n",
    "    df_aligned = df.iloc[:len(labels)] \n",
    "    # üåü ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡πÉ‡∏ä‡πâ .ffill() ‡πÅ‡∏ó‡∏ô fillna(method='ffill') \n",
    "    data = df_aligned[features_cols].ffill().values \n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "    X, y = [], []\n",
    "    for i in range(len(data_scaled) - seq_len):\n",
    "        X.append(data_scaled[i:i+seq_len])\n",
    "        y.append(labels[i+seq_len]) \n",
    "        \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    if len(X) == 0:\n",
    "        raise ValueError(\"Sequence length is too long for the given data. Check seq_len and data length.\")\n",
    "        \n",
    "    return X, y, scaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730937e8",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£  CNN-LSTM  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f837a864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_lstm_model(seq_len, n_features, n_classes=2):\n",
    "\n",
    "    model = Sequential([\n",
    "        # 1. CNN Section: ‡∏î‡∏∂‡∏á Local Features\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(seq_len, n_features)),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # 2. LSTM Section: ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ Temporal Dependencies\n",
    "        LSTM(64, activation='tanh'),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        # 3. Dense Section: Classification\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(n_classes, activation='softmax') # n_classes=2\n",
    "    ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2ac297",
   "metadata": {},
   "source": [
    "# 7Ô∏è‚É£ Pipeline train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "948227a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pipeline(symbol='PTT.BK', cass_limit=1200, seq_len=30, epochs=10, future_days=1):\n",
    "    \"\"\"‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÅ‡∏•‡∏∞‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•\"\"\"\n",
    "    print(f\"1. ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {symbol} (Limit: {cass_limit} ‡∏ß‡∏±‡∏ô)...\")\n",
    "    df = get_candlestick_data(symbol, limit=cass_limit)\n",
    "    \n",
    "    print(f\"2. ‡∏™‡∏£‡πâ‡∏≤‡∏á Label ‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á ({future_days} ‡∏ß‡∏±‡∏ô‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤)...\")\n",
    "    labels = create_direction_labels(df['close'], future_days=future_days)\n",
    "    \n",
    "    print(\"3. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Sequence ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö DL...\")\n",
    "    X, y, scaler = preprocess_and_create_sequences(df, labels, seq_len)\n",
    "    \n",
    "    print(f\"   Shape X: {X.shape}, Shape y: {y.shape}\")\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "    y_train_cat = to_categorical(y_train, 2)\n",
    "    y_val_cat = to_categorical(y_val, 2)\n",
    "\n",
    "    print(\"4. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Class Weight ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•...\")\n",
    "    cw = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "    cw = {i: w for i, w in enumerate(cw)}\n",
    "\n",
    "    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ: ‡πÉ‡∏ä‡πâ CNN-LSTM Model\n",
    "    model = build_cnn_lstm_model(seq_len, X.shape[2], n_classes=2) \n",
    "    \n",
    "    print(f\"5. ‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• (Epochs: {epochs})...\")\n",
    "    model.fit(X_train, y_train_cat,\n",
    "              validation_data=(X_val, y_val_cat),\n",
    "              epochs=epochs, batch_size=32,\n",
    "              class_weight=cw, verbose=2)\n",
    "              \n",
    "    return model, df, scaler, X_val, y_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278d87b1",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Plot Forecast: ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤‡∏à‡∏£‡∏¥‡∏á + ‡πÄ‡∏™‡πâ‡∏ô‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bae62aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_future_direction_forecast(df_original, model, scaler, seq_len, symbol='SYMBOL', forecast_steps=10):\n",
    "\n",
    "    # --- 1. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï ---\n",
    "    \n",
    "    start_date = df_original.index[-1]\n",
    "    start_price = df_original['close'].iloc[-1]\n",
    "    \n",
    "    features_cols = ['open', 'high', 'low', 'close', 'volume']\n",
    "    data_last = df_original[features_cols].ffill().values \n",
    "    data_scaled_full = scaler.transform(data_last)\n",
    "    \n",
    "    last_sequence_scaled = data_scaled_full[-seq_len:]\n",
    "    \n",
    "    # --- 2. ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á 10 ‡∏ß‡∏±‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ (‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÅ‡∏ö‡∏ö‡∏Å‡πâ‡∏≤‡∏ß‡∏´‡∏ô‡πâ‡∏≤) ---\n",
    "    \n",
    "    forecast_dates = pd.date_range(start=start_date, periods=forecast_steps + 1)\n",
    "    \n",
    "    forecast_prices = [start_price]\n",
    "    current_price = start_price\n",
    "    current_sequence = last_sequence_scaled.copy() \n",
    "\n",
    "    print(\"\\n--- Forecast Simulation ---\")\n",
    "    for i in range(forecast_steps):\n",
    "        # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏ñ‡∏±‡∏î‡πÑ‡∏õ‡∏à‡∏≤‡∏Å Sequence ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô\n",
    "        X_predict = np.expand_dims(current_sequence, axis=0)\n",
    "        y_pred_proba = model.predict(X_predict, verbose=0)\n",
    "        next_direction = np.argmax(y_pred_proba, axis=1)[0]\n",
    "        \n",
    "        # ‚ö†Ô∏è Assumption: ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤ +/- 1%\n",
    "        price_change_rate = 0.01 \n",
    "        if next_direction == 1: # Up\n",
    "            next_price = current_price * (1 + price_change_rate)\n",
    "        else: # Down/Flat (0)\n",
    "            next_price = current_price * (1 - price_change_rate)\n",
    "\n",
    "        forecast_prices.append(next_price)\n",
    "\n",
    "        # 3.1. ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï Sequence ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏£‡∏≠‡∏ö‡∏ñ‡∏±‡∏î‡πÑ‡∏õ\n",
    "        last_features = current_sequence[-1].copy() \n",
    "        last_features_unscaled = scaler.inverse_transform(np.expand_dims(last_features, axis=0))[0]\n",
    "        last_features_unscaled[-2] = next_price # Close Price ‡∏Ñ‡∏∑‡∏≠ index -2 \n",
    "        new_features_scaled = scaler.transform(np.expand_dims(last_features_unscaled, axis=0))[0]\n",
    "        \n",
    "        # ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô Sequence: ‡∏ó‡∏¥‡πâ‡∏á‡∏ß‡∏±‡∏ô‡πÅ‡∏£‡∏Å ‡πÅ‡∏•‡∏∞‡∏ï‡πà‡∏≠‡∏î‡πâ‡∏ß‡∏¢‡∏ß‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà\n",
    "        current_sequence = np.concatenate([current_sequence[1:], np.expand_dims(new_features_scaled, axis=0)], axis=0)\n",
    "\n",
    "        current_price = next_price # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô\n",
    "        \n",
    "        \n",
    "    # --- 3. ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≤‡∏ü ---\n",
    "    \n",
    "    plt.style.use('dark_background')\n",
    "    fig, ax = plt.subplots(figsize=(15, 7), facecolor='black')\n",
    "    \n",
    "    # 3.1. ‡∏ß‡∏≤‡∏î‡∏£‡∏≤‡∏Ñ‡∏≤‡∏à‡∏£‡∏¥‡∏á (‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î)\n",
    "    ax.plot(df_original.index, df_original['close'], \n",
    "            color='dodgerblue', linewidth=2, label='Actual Close Price', zorder=1)\n",
    "\n",
    "    # 3.2. ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå (Forecast)\n",
    "    forecast_dates_full = list(df_original.index[-1:]) + list(forecast_dates[1:])\n",
    "    \n",
    "    for i in range(forecast_steps):\n",
    "        p1 = forecast_prices[i]\n",
    "        p2 = forecast_prices[i+1]\n",
    "        d1 = forecast_dates_full[i]\n",
    "        d2 = forecast_dates_full[i+1]\n",
    "        \n",
    "        color = 'green' if p2 > p1 else 'red'\n",
    "        \n",
    "        ax.plot([d1, d2], [p1, p2], \n",
    "                color=color, linewidth=4, linestyle='--', zorder=5, \n",
    "                label='CNN-LSTM Forecast' if i == 0 else None) # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï Label\n",
    "        \n",
    "    # 3.3. ‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô Forecast\n",
    "    ax.axvline(start_date, color='yellow', linestyle='-', linewidth=1, label='Forecast Start Date')\n",
    "    ax.scatter(start_date, start_price, color='yellow', s=100, marker='o', zorder=6)\n",
    "\n",
    "    # --- ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏Å‡∏£‡∏≤‡∏ü ---\n",
    "    ax.set_title(f\"{symbol} - CNN-LSTM Direction Forecast ({forecast_steps} Days Ahead)\", \n",
    "                 color='white', fontsize=16, pad=20)\n",
    "    ax.set_xlabel(\"Date\", color='white', fontsize=12)\n",
    "    ax.set_ylabel(\"Price\", color='white', fontsize=12)\n",
    "    \n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    ax.xaxis.set_major_locator(mdates.DayLocator(interval=max(1, len(df_original)//10)))\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    ax.tick_params(axis='x', colors='white')\n",
    "    ax.tick_params(axis='y', colors='white')\n",
    "    ax.grid(True, color='gray', linestyle='--', alpha=0.4)\n",
    "    ax.legend(facecolor='black', edgecolor='white', loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62592cb",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Plot Classic Pattern (‡∏ß‡∏≤‡∏î H&S/IH&S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f77d0539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classic_pattern(df, patterns, symbol='SYMBOL'):\n",
    "\n",
    "    plt.style.use('dark_background')\n",
    "    patterns_to_plot = patterns[-1:] # ‡πÅ‡∏™‡∏î‡∏á Pattern ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î 1 ‡∏≠‡∏±‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô\n",
    "\n",
    "    if not patterns_to_plot:\n",
    "        print(f\"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö H&S/IH&S ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏ô‡∏Å‡∏£‡∏≤‡∏ü\")\n",
    "        return\n",
    "\n",
    "    for p in patterns_to_plot:\n",
    "        fig, ax = plt.subplots(figsize=(15, 7), facecolor='black')\n",
    "        prices = df['close'].values\n",
    "        dates = df.index\n",
    "        \n",
    "        # 1. ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏¥‡∏î (Close Price)\n",
    "        ax.plot(dates, prices, color='dodgerblue', linewidth=2, marker='.', markersize=4, label='Close Price', zorder=1)\n",
    "\n",
    "        # 2. ‡∏ß‡∏≤‡∏î‡∏à‡∏∏‡∏î Pattern (L, H, R) ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤\n",
    "        points_idx = [p['l'], p['h'], p['r']]\n",
    "        points_price = prices[points_idx]\n",
    "        pattern_color = 'red' if p['type'] == 'H&S' else 'green' # ‡∏™‡∏µ‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó Pattern\n",
    "        \n",
    "        ax.scatter(dates[points_idx], points_price,\n",
    "                   color=pattern_color, \n",
    "                   s=150, edgecolors='white', marker='o', zorder=5, label=f\"{p['type']} Points\")\n",
    "        \n",
    "        # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏à‡∏∏‡∏î (Left, Head, Right)\n",
    "        labels = ['Left', 'Head', 'Right']\n",
    "        for i, idx in enumerate(points_idx):\n",
    "            ax.text(dates[idx], points_price[i] * 1.001, f\"{labels[i]}\\n{points_price[i]:.2f}\",\n",
    "                     color='white', fontsize=9, fontweight='bold',\n",
    "                     ha='center', va='bottom', zorder=6, \n",
    "                     bbox=dict(facecolor='black', alpha=0.6, pad=2, edgecolor=pattern_color))\n",
    "        \n",
    "        # 3. ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô Neckline (‡∏•‡∏≤‡∏Å‡∏¢‡∏≤‡∏ß‡∏ñ‡∏∂‡∏á‡∏™‡∏∏‡∏î‡∏Å‡∏£‡∏≤‡∏ü)\n",
    "        t1, t2 = p['t1'], p['t2']\n",
    "        t1_date = dates[t1]\n",
    "        t1_price = prices[t1]\n",
    "        \n",
    "        neck_slope = (prices[t2] - t1_price) / (t2 - t1) if t2 != t1 else 0\n",
    "        \n",
    "        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏≤‡∏Ñ‡∏≤ Neckline ‡∏ó‡∏µ‡πà‡∏à‡∏∏‡∏î‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏Å‡∏£‡∏≤‡∏ü (‡∏•‡∏≤‡∏Å‡∏¢‡∏≤‡∏ß)\n",
    "        final_neck_price = t1_price + neck_slope * (len(df.index) - 1 - t1)\n",
    "        \n",
    "        ax.plot([t1_date, dates[-1]], \n",
    "                [t1_price, final_neck_price],\n",
    "                color='lime', linewidth=3, linestyle='--', label='Neckline', zorder=2)\n",
    "                \n",
    "        # 4. ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô Target Price (‡πÄ‡∏™‡πâ‡∏ô‡πÅ‡∏ô‡∏ß‡∏ô‡∏≠‡∏ô) ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤\n",
    "        target_price = p['target_price']\n",
    "        \n",
    "        # Target Price Line (‡πÄ‡∏™‡πâ‡∏ô‡πÅ‡∏ô‡∏ß‡∏ô‡∏≠‡∏ô)\n",
    "        ax.axhline(target_price, color='gold', linestyle=':', linewidth=2, label=f\"Target Price: {target_price:.2f}\", zorder=1)\n",
    "        \n",
    "        # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç Target Price ‡∏ö‡∏ô‡∏Å‡∏£‡∏≤‡∏ü\n",
    "        ax.text(dates[-1], target_price, f\"TARGET: {target_price:.2f}\", \n",
    "                color='gold', fontsize=12, fontweight='bold', \n",
    "                verticalalignment='center', horizontalalignment='right',\n",
    "                bbox=dict(facecolor='black', alpha=0.7, pad=4))\n",
    "        \n",
    "        # 5. ‡∏ß‡∏≤‡∏î‡∏à‡∏∏‡∏î Breakout Point (‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡∏Ç‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°)\n",
    "        break_idx = p['break_idx']\n",
    "        break_date = dates[break_idx]\n",
    "        break_price = prices[break_idx]\n",
    "        \n",
    "        ax.scatter(break_date, break_price, \n",
    "                   color='yellow', s=150, marker='*', edgecolors='black', \n",
    "                   zorder=6, label='Breakout Point')\n",
    "        \n",
    "        # --- ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏Å‡∏£‡∏≤‡∏ü ---\n",
    "        ax.set_title(f\"{symbol} - CLASSIC {p['type']} Pattern Detection (Target: {target_price:.2f})\", color='white', fontsize=18, pad=20)\n",
    "        ax.set_xlabel(\"Date\", color='white', fontsize=12)\n",
    "        ax.set_ylabel(\"Price\", color='white', fontsize=12)\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        ax.grid(True, color='gray', linestyle='--', alpha=0.4)\n",
    "        \n",
    "        # ‡∏Å‡∏£‡∏≠‡∏á Legend ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÄ‡∏â‡∏û‡∏≤‡∏∞ 5 ‡∏≠‡∏á‡∏Ñ‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏´‡∏•‡∏±‡∏Å (‡πÄ‡∏û‡∏¥‡πà‡∏° Breakout Point)\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        unique_labels = {}\n",
    "        for h, l in zip(handles, labels):\n",
    "            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ Label ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡πÉ‡∏ô 5 ‡∏≠‡∏á‡∏Ñ‡πå‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n",
    "            if l in ['Close Price', f\"{p['type']} Points\", 'Neckline', 'Breakout Point'] or l.startswith('Target Price:'):\n",
    "                unique_labels[l] = h\n",
    "        \n",
    "        # ‡∏õ‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• Legend ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏°\n",
    "        ax.legend(unique_labels.values(), unique_labels.keys(), facecolor='black', edgecolor='white', loc='upper left')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe09f832",
   "metadata": {},
   "source": [
    "# üîü ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (‡∏£‡∏ß‡∏° Classic Pattern ‡πÅ‡∏•‡∏∞ DL Forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40d704a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- üß† ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• CNN-LSTM ---\n",
      "1. ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PTT.BK (Limit: 100 ‡∏ß‡∏±‡∏ô)...\n",
      "Error connecting to Cassandra: ('Unable to connect to any servers', {'127.0.0.1:9042': ConnectionRefusedError(61, \"Tried connecting to [('127.0.0.1', 9042)]. Last error: Connection refused\")})\n",
      "\n",
      "‚ùå ‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: Could not connect to Cassandra. Check if it's running.\n",
      "‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ Cassandra Server (127.0.0.1:9042) ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        # --- Config ---\n",
    "        symbol = \"PTT.BK\"\n",
    "        DATA_LIMIT = 100  # ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏¢‡∏≠‡∏∞‡∏Ç‡∏∂‡πâ‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å LSTM\n",
    "        SEQUENCE_LENGTH = 30\n",
    "        FUTURE_DAYS = 1   # ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ (1 ‡∏ß‡∏±‡∏ô)\n",
    "        EPOCHS = 5\n",
    "        \n",
    "        # 1. ‡∏£‡∏±‡∏ô Pipeline (‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á 0/1)\n",
    "        print(\"\\n--- üß† ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ù‡∏∂‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• CNN-LSTM ---\")\n",
    "        model, df_original, scaler, X_val, y_val = train_pipeline(\n",
    "            symbol=symbol, \n",
    "            cass_limit=DATA_LIMIT, \n",
    "            seq_len=SEQUENCE_LENGTH, \n",
    "            epochs=EPOCHS,\n",
    "            future_days=FUTURE_DAYS\n",
    "        ) \n",
    "\n",
    "        # 2. ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏• (‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á)\n",
    "        y_pred = model.predict(X_val, verbose=0)\n",
    "        y_pred_cls = np.argmax(y_pred, axis=1)\n",
    "        print(\"\\n--- Model Evaluation (Validation Set) ---\")\n",
    "        print(classification_report(y_val, y_pred_cls, target_names=['0: Down/Flat', '1: Up'], zero_division=0))\n",
    "\n",
    "        # 3. ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü Price Direction Forecast (CNN-LSTM)\n",
    "        print(\"\\n--- üìà ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü Price Direction Forecast (CNN-LSTM) ---\")\n",
    "        plot_future_direction_forecast(\n",
    "            df_original, \n",
    "            model, \n",
    "            scaler, \n",
    "            seq_len=SEQUENCE_LENGTH, \n",
    "            symbol=symbol, \n",
    "            forecast_steps=10\n",
    "        )\n",
    "        \n",
    "        # 4. ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• Classic Pattern (H&S/IH&S)\n",
    "        print(\"\\n--- üìâ ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü Classic Pattern (H&S/IH&S) ---\")\n",
    "        classic_patterns = detect_head_shoulders(df_original, distance=5, tolerance=0.03)\n",
    "        print(f\"‡∏û‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö H&S/IH&S ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(classic_patterns)} ‡∏à‡∏∏‡∏î\")\n",
    "        \n",
    "        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß\n",
    "        plot_classic_pattern(df_original, classic_patterns, symbol=symbol)\n",
    "        \n",
    "    except ConnectionRefusedError as e:\n",
    "        print(f\"\\n‚ùå ‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {e}\")\n",
    "        print(\"‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ Cassandra Server (127.0.0.1:9042) ‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà\")\n",
    "    except ValueError as e:\n",
    "        print(f\"\\n‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡∏Ñ‡∏¥‡∏î: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
